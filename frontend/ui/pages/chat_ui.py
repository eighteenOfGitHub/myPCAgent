# frontend/ui/pages/chat_ui.py
import gradio as gr

from frontend.handlers.chat_handler import (
    load_session_list,
    create_new_session,
    load_messages,
    stream_chat
)
from frontend.handlers.llm_setting_handler import build_choices_from_configs

def render(llm_configs_state=None, default_id_state=None):
    """èŠå¤©é¡µé¢ï¼šä¼šè¯ç®¡ç† + å¯¹è¯äº¤äº’ï¼ˆå«å®Œæ•´äº‹ä»¶ç»‘å®šï¼‰"""
    
    # --- è¾…åŠ©å‡½æ•°ï¼ˆæ•°æ®/äº‹ä»¶é€»è¾‘ï¼‰ ---
    def _resolve_default_model_info(configs, default_id):
        """ä»é…ç½®åˆ—è¡¨ä¸­è§£æé»˜è®¤æ¨¡å‹ä¿¡æ¯"""
        for cfg in configs or []:
            if str(cfg.get("id")) == str(default_id):
                model = cfg.get("model_name") or "â€”"
                provider = cfg.get("provider") or "â€”"
                return model, provider
        return "â€”", "â€”"
    
    def _load_sessions():
        """åŠ è½½å†å²ä¼šè¯åˆ—è¡¨"""
        sessions = load_session_list()
        return gr.update(choices=sessions)

    # è·å–åˆå§‹å€¼ç”¨äºä¸‹æ‹‰æ¡†
    initial_configs = llm_configs_state.value if llm_configs_state else []
    initial_default_id = default_id_state.value if default_id_state else None
    initial_choices = build_choices_from_configs(initial_configs, initial_default_id)

    # --- UI å¸ƒå±€ ---
    with gr.Row():
        # å·¦ä¾§ï¼šä¼šè¯æ§åˆ¶é¢æ¿
        with gr.Column(scale=1, min_width=180):
            gr.Markdown("### ğŸ’¬ ä¼šè¯ç®¡ç†")
            session_dropdown = gr.Dropdown(
                label="å†å²ä¼šè¯",
                choices=[],  # åˆå§‹ä¸ºç©ºï¼Œç”± .load() å¡«å……
                interactive=True,
                value=None
            )
            new_session_btn = gr.Button("ğŸ†• æ–°å»ºä¼šè¯", variant="primary", size="sm")
            delete_session_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤ä¼šè¯", variant="stop", size="sm")
            
            gr.Markdown("### âš™ï¸ å½“å‰é…ç½®")
            current_model_dropdown = gr.Dropdown(
                label="å½“å‰æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰",
                choices=initial_choices,
                value=initial_default_id,
                interactive=False,
                allow_custom_value=False,
            )

        # å³ä¾§ï¼šèŠå¤©åŒºåŸŸ
        with gr.Column(scale=7):
            chatbot = gr.Chatbot(
                elem_id="chat_display",
                height=500,
                label="å¯¹è¯å†å²",
                type="messages",
            )
            msg_input = gr.Textbox(
                label="è¾“å…¥æ¶ˆæ¯",
                placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ŒæŒ‰å›è½¦æˆ–ç‚¹å‡»å‘é€...",
                lines=1
            )
            with gr.Row():
                send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary")
                clear_btn = gr.Button("ğŸ§¹ æ¸…ç©º")

    # çŠ¶æ€ç®¡ç†
    session_id_state = gr.State(None)
    chat_history_state = gr.State([])
    if llm_configs_state is None:
        llm_configs_state = gr.State(value=[])
    if default_id_state is None:
        default_id_state = gr.State(value=None)

    # --- æ§ä»¶ç»‘å®šï¼ˆé›†ä¸­æ³¨å†Œï¼‰ ---
    # 1. æ–°å»ºä¼šè¯
    new_session_btn.click(
        create_new_session,
        inputs=[],
        outputs=[
            session_dropdown,
            session_id_state,
            chat_history_state,
            chatbot
        ],
        show_progress="minimal"
    )

    # 2. åˆ‡æ¢ä¼šè¯
    session_dropdown.change(
        load_messages,
        inputs=[session_dropdown],
        outputs=[chat_history_state, chatbot],
        show_progress="minimal"
    ).then(
        lambda sid: sid,
        inputs=[session_dropdown],
        outputs=[session_id_state]
    )

    # 3. å‘é€æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
    send_event = send_btn.click(
        stream_chat,
        inputs=[session_id_state, msg_input, chat_history_state],
        outputs=[chatbot],
        queue=True,
        show_progress="minimal"
    ).then(
        lambda: "", None, msg_input
    ).then(
        lambda hist: hist, [chatbot], chat_history_state
    )

    # 4. å›è½¦å‘é€
    msg_input.submit(
        stream_chat,
        inputs=[session_id_state, msg_input, chat_history_state],
        outputs=[chatbot],
        queue=True,
        show_progress="minimal"
    ).then(
        lambda: "", None, msg_input
    ).then(
        lambda hist: hist, [chatbot], chat_history_state
    )

    # é¡µé¢é¦–æ¬¡åŠ è½½æ—¶è·å–ä¼šè¯åˆ—è¡¨
    # æ³¨æ„ï¼šéœ€è¦åœ¨ .load() ä¸­å¼•ç”¨ç»„ä»¶ï¼Œæ— æ³•åœ¨ç»„ä»¶å®šä¹‰å‰æ·»åŠ 
    
    return session_dropdown, current_model_dropdown

