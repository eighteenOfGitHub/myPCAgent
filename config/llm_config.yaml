# config/llm_config.yaml
# 千问系列模型：https://help.aliyun.com/zh/model-studio/models
# 查看LiteLLM支持的提供商和模型：https://docs.litellm.ai/docs/providers

llm_pool:
  - name: "gpt-oss:120b-cloud-by-ollama"
    model: "ollama/gpt-oss:120b-cloud"
    type: "online"
    tags: ["general", "chat"]
    enabled: true
    api_base: "http://localhost:11434"
    api_key_env: null
    priority: 10

  - name: "ollama/qwen3-coder:480b-cloud"
    model: "ollama/qwen3-coder:480b-cloud"
    type: "online"
    tags: ["coding"]
    enabled: true
    api_base: "http://localhost:11434"
    api_key_env: null
    priority: 9

  - name: "ollama/qwen2.5-coder:1.5b-base"
    model: "ollama/qwen2.5-coder:1.5b-base"
    type: "local"
    tags: ["coding"]
    enabled: true
    api_base: "http://localhost:11434"
    api_key_env: null
    priority: 9

  - name: "qwen3:8b-local"
    model: "ollama/qwen3:8b"
    type: "local"
    tags: ["general", "chat", "route", "tools"]
    enabled: true
    api_base: "http://localhost:11434"
    api_key_env: null
    priority: 5

  - name: "qwen-plus-online"
    model: "qwen-plus"
    type: "online"
    tags: ["general", "chat", "route", "coding", "reasoning" ,"tools"]
    enabled: true
    api_base: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    api_key_env: "API_KEY_DASHSCOPE"
    priority: 1

  - name: "deepseek-chat-online"
    model: "deepseek-chat"
    type: "online"
    tags: ["general", "chat"]
    enabled: true
    api_base: "https://api.deepseek.com"
    api_key_env: "API_KEY_DEEPSEEK"
    priority: 9

  - name: "deepseek-reasoner-online"
    model: "deepseek-reasoner" 
    type: "online"
    tags: ["general", "reasoning"]
    enabled: true
    api_base: "https://api.deepseek.com"
    api_key_env: "API_KEY_DEEPSEEK"
    priority: 8

  # --- 路由专用模型 ---
  - name: "qwen-turbo-online"
    model: "qwen-turbo-online"
    type: "online"
    tags: ["route"] # 专门为 route 任务类型
    enabled: true
    api_base: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    api_key_env: "API_KEY_DASHSCOPE"
    priority: 3

  - name: "ollma/llama3.2:1b"
    model: "ollma/llama3.2:1b"
    type: "local"
    tags: ["route"] # 专门为 route 任务类型
    enabled: true
    api_base: "http://localhost:11434"
    api_key_env: null
    priority: 3

  # --- 语音模型 ---

  # - name: "gpt-4o-mini-route"         # (str) 在配置和日志中引用此模型的唯一标识
  #   model: "gpt-4o-mini"              # (str) 传递给 litellm 的实际模型名称
  #   type: "online"                    # (str) 模型部署类型，可选项: "local"(本地), "online"(远程API)
  #   tags: ["route"]                   # (List[str]) 标签，常见可选项: "general"(通用), "chat"(聊天), "coding"(代码),  "reasoning"(推理),
                                                                      #"route"(路由), "tts"(文本转语音), "asr"(自动语音识别)
  #   enabled: true                     # (bool) 启用状态，设为 true 表示此模型可用
  #   api_base: null                    # (Optional[str]) API 基础地址，null 表示使用 litellm 预设的默认地址
  #   api_key_env: "OPENAI_API_KEY"     # (str) API 密钥环境变量名，从该变量读取密钥
  #   priority: 15                      # (int) 调用优先级，数值越小优先级越高 (15 表示相对较低)

routing:
  default_mode: "online" # 可以是 online 或 local
  selection_strategy: "priority" # 当前仅支持 priority
  retry_on_failure: true
  max_total_attempts: 3 # 包括 litellm 内部重试

# --- 更新 defaults.mapping 以包含新的任务类型 ---
defaults:
  mapping:
    general:
      online: "qwen-plus-online"
      local: "qwen3:8b-local"
    coding:
      online: "ollama/qwen3-coder:480b-cloud"
      local: "ollama/qwen2.5-coder:1.5b-base"
    # --- 路由任务的默认模型 ---
    route: # 为路由决策指定模型
      online: "qwen-turbo-online" # 使用更小更快的模型
      local: "ollma/llama3.2:1b"
    # --- 语音任务的默认模型 ---
    # asr: # 语音识别
    #   online: "whisper-online"
    #   local: "faster-whisper-local" # 如果启用了本地模型
    # tts: # 语音合成
    #   online: "tts-openai-online"
    #   local: "edge-tts-local" # 如果启用了本地模型